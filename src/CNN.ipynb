{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31a021a-f045-410f-9cd5-4e967a0c9f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS NOTEBOOK IS HONESTLY JUST HERE TO MESS WITH TO UNDERSTAND NNs BETTER BY IMPLEMENTING FROM SCRATCH\n",
    "# IDK IF WE SHOULD TRY AND GET THIS FULLY WORKING BECAUSE COWAN MIGHT NOT THINK ITS MY CODE\n",
    "# (because people in this class somehow get 27% accuracy on a 1/4 chance and he thinks we're all that dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4bddaa-1b63-48c7-aa25-e8715448fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util.helper_functions import *\n",
    "from util.ImageGeneration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abc43da-e720-4871-a169-0391e97b58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    \"\"\"\n",
    "    Represents the Convolutional Layer to the NN\n",
    "    params:\n",
    "        num_kernels : number of filters to \"scan\" with\n",
    "        kernel-size : size of each filter, this is 3x3 \n",
    "        stride : how many steps to take between \"scans\" (1)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_kernels, kernel_size, stride = 1):\n",
    "\n",
    "        # General Init\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.weights = np.random.randn(num_kernels, kernel_size, kernel_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"Forward pass of the convolution layer\"\"\"\n",
    "        examples, w, _, channels = input_data.shape\n",
    "        \n",
    "        kernels = self.num_kernels\n",
    "        k_size = self.kernel_size\n",
    "\n",
    "        # Output Init\n",
    "        output_size = ((w - k_size) // self.stride) + 1\n",
    "        output = np.zeros((examples, kernels, output_size, output_size, channels))\n",
    "\n",
    "        # Compute the feature map for each kernel (same as helpers.apply_convolution, but allows > 1 kernel)\n",
    "        for n in range(examples):\n",
    "            for k in range(kernels):\n",
    "                for i in range(w - k_size + 1):\n",
    "                    for j in range(w - k_size + 1):\n",
    "                        region = input_data[n, i : i + k_size, j : j + k_size]\n",
    "                        for c in range(channels):\n",
    "                            output[n, k, i, j, c] += np.sum(self.weights[k, :, :] * region[:, :, c])\n",
    "                            \n",
    "        return relu(output)\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff120e7-d419-444f-9ced-929d601e6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingLayer:\n",
    "    \"\"\"\n",
    "    Represents the Pooling (mean pooling) Layer of the NN\n",
    "    params:\n",
    "        pool-size : size of subsection to take the mean of \n",
    "        stride : how many steps to take (pool size usually)\n",
    "    \"\"\"\n",
    "    def __init__(self, pool_size, stride = None):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = pool_size if stride is None else stride\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"Forward pass of the pooling layer, (mean pooling)\"\"\"\n",
    "        examples, feature_maps, w, _, channels = input_data.shape\n",
    "\n",
    "        p = self.pool_size\n",
    "        output_size = ((w - p) // self.stride) + 1\n",
    "        output = np.zeros((examples, feature_maps, output_size, output_size, channels))\n",
    "        for n in range(examples):\n",
    "            for k in range(feature_maps):\n",
    "                for i in range(0, w - p + 1, self.stride):\n",
    "                    for j in range(0, w - p + 1, self.stride):\n",
    "                        region = input_data[n, k, i : i + p, j : j + p]\n",
    "                        for c in range(channels):\n",
    "                            output[n, k, i // p, j // p, c] = np.mean(region[:, :, c])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef23cc4d-5bcb-4d75-97d3-d8bcd5720ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedLayer:\n",
    "    \"\"\"\n",
    "    This is the actual input layer to the model, basically just applies softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        self.weights = np.zeros((num_classes, input_size))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        flattened = input_data.reshape(input_data.shape[0], -1)\n",
    "        dot_product = np.dot(self.weights, flattened.T)\n",
    "        return softmax(dot_product)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d705fe83-ac07-48e5-b985-f2b6a162bc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataSet()\n",
    "img_gen = ImageGenerator(1000, dataset = data, seed = 1)\n",
    "input_data = np.array(data.image_data)\n",
    "input_data = one_hot_encode(input_data)\n",
    "row_col = row_col_features(input_data)\n",
    "load_image(data, 0).display()\n",
    "row_col[0, :20, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b237418-3d42-4c8a-a63f-70d05acc8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [ConvLayer(1, 3), PoolingLayer(2), ConnectedLayer(324, 4)]\n",
    "last_output = input_data\n",
    "for layer in layers:\n",
    "    last_output = layer.forward(last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48e8203d-a8c4-4b42-8e3c-5dfd6b061fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.25, 0.25, ..., 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, ..., 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, ..., 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, ..., 0.25, 0.25, 0.25]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54a768-0cc1-473c-aba0-5f6a05fbe4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
