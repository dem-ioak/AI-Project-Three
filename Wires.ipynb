{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fa14f-8d79-4759-8ec9-1f04bee37702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9698e-658f-4fcd-a55b-900fe909245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enums\n",
    "class Color(Enum):\n",
    "    RED = 0\n",
    "    BLUE = 1\n",
    "    YELLOW = 2\n",
    "    GREEN = 3\n",
    "    BLACK = 4\n",
    "\n",
    "class Label(Enum):\n",
    "    DANGEROUS = 0\n",
    "    SAFE = 1\n",
    "\n",
    "COLOR_TO_RGB = {\n",
    "    0 : (255, 0, 0),\n",
    "    1 : (0, 0, 255),\n",
    "    2 : (255, 255, 0),\n",
    "    3 : (0, 255, 0),\n",
    "    4 : (0, 0, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f086b-13da-454e-a629-8b2b154f8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generation\n",
    "class Image: # USE THIS CLASS TO DISPLAY / CREATE IMAGE\n",
    "    def __init__(self, data, label, third_wire):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.third_wire = third_wire\n",
    "\n",
    "    def display(self):\n",
    "        n = self.data.shape[0]\n",
    "        image_data = [[0 for _ in range(n)] for _ in range(n)]\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                curr_val = self.data[i][j]\n",
    "                image_data[i][j] = COLOR_TO_RGB[curr_val]\n",
    "\n",
    "        plt.imshow(image_data)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.image_data = []\n",
    "        self.labels = []\n",
    "        self.third_wires = []\n",
    "\n",
    "    def add_image(self, image, label, third_wire):\n",
    "        \"\"\"Add an image to the dataset using raw data\"\"\"\n",
    "        self.image_data.append(image)\n",
    "        self.labels.append(label.value)\n",
    "        self.third_wires.append(third_wire) \n",
    "\n",
    "class ImageGenerator:\n",
    "    \"\"\"Generates N (M x M) images and writes to data\"\"\"\n",
    "    def __init__(self, num_images, dimensions = 20, write_path = None, dataset = None, seed = None):\n",
    "        self.dimensions = dimensions\n",
    "        self.seed = seed\n",
    "        random.seed(seed)\n",
    "        for _ in range(num_images):\n",
    "            data, label, third_wire = self.generate(write_path is not None)\n",
    "            if dataset is not None:\n",
    "                dataset.add_image(data, label, third_wire)\n",
    "\n",
    "            # TODO: Write to data (may not be necessary, gen is really fast)\n",
    "            if write_path is not None:\n",
    "                pass\n",
    "\n",
    "    def generate(self, write_ = False):\n",
    "        \"\"\"Generate a single image and label it appropriately\"\"\"\n",
    "        n = self.dimensions\n",
    "        image_data = np.full((n, n), Color.BLACK.value)\n",
    "        colors = [Color.RED, Color.BLUE, Color.YELLOW, Color.GREEN]\n",
    "\n",
    "        # Keep track of rows/cols that can be used\n",
    "        valid_rows = list(range(n))\n",
    "        valid_cols = list(range(n))\n",
    "\n",
    "        # 1  = Color Row\n",
    "        # -1 = Color Col\n",
    "        pointer = random.choice([1, -1])\n",
    "        label = Label.SAFE\n",
    "        yellow_placed = False\n",
    "        third_wire = None\n",
    "\n",
    "        for i in range(4):\n",
    "            # Select a unused color\n",
    "            curr_color = random.choice(colors)\n",
    "            colors.remove(curr_color)\n",
    "\n",
    "            # Determine which should be cut (if dangerous)\n",
    "            if i == 2:\n",
    "                third_wire = curr_color\n",
    "            \n",
    "            # Handle marking an image as DANGEROUS if red is placed before yellow\n",
    "            yellow_placed = yellow_placed or curr_color == Color.YELLOW\n",
    "            if curr_color == Color.RED and not yellow_placed:\n",
    "                label = Label.DANGEROUS\n",
    "\n",
    "            if pointer == 1:\n",
    "                rand_idx = random.choice(valid_rows)\n",
    "                valid_rows.remove(rand_idx)\n",
    "                self.color_row(rand_idx, curr_color, image_data)\n",
    "            else:\n",
    "                rand_idx = random.choice(valid_cols)\n",
    "                valid_cols.remove(rand_idx)\n",
    "                self.color_column(rand_idx, curr_color, image_data)\n",
    "                \n",
    "            pointer *= -1\n",
    "        \n",
    "        return image_data, label, third_wire\n",
    "            \n",
    "\n",
    "    def color_column(self, col, color, arr):\n",
    "        \"\"\"Color the given column of the image with the provided color\"\"\"\n",
    "        n = self.dimensions\n",
    "        for i in range(n):\n",
    "            arr[i][col] = color.value\n",
    "\n",
    "    def color_row(self, row, color, arr):\n",
    "        \"\"\"Color the given row of the image with the provided color\"\"\"\n",
    "        n = self.dimensions\n",
    "        for i in range(n):\n",
    "            arr[row][i] = color.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c49a5c-64ff-4c9d-840e-3b2e173d805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def load_image(dataset_obj, index):\n",
    "    \"\"\"Load a specific index of the dataset\"\"\"\n",
    "    image_data = dataset_obj.image_data[index]\n",
    "    label = dataset_obj.labels[index]\n",
    "    third_wire = dataset_obj.third_wires[index]\n",
    "    img = Image(image_data, label, third_wire)\n",
    "    return img\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def train_test_validation_split(X, y, train_size = .8, test_size = .1, validation_size = .1):\n",
    "    if train_size + test_size + validation_size != 1:\n",
    "        print(\"Error: train + test + validation don't add up to 1.\")\n",
    "        return\n",
    "    \n",
    "    print(X.shape)\n",
    "    examples, features = X.shape\n",
    "    # Randomize Indexes\n",
    "    index_array = np.arange(examples)\n",
    "    random.shuffle(index_array)\n",
    "\n",
    "    # Split up data\n",
    "    num_training = int(examples * train_size)\n",
    "    num_testing = int(examples * test_size)\n",
    "    train_indices = index_array[:num_training]\n",
    "    test_indices = index_array[num_training:(num_training + num_testing)]\n",
    "    validation_indices = index_array[(num_training + num_testing):]\n",
    "    \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    X_validation = X[validation_indices]\n",
    "    y_validation = y[validation_indices]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_validation, y_validation\n",
    "\n",
    "def one_hot_encode(image_data):\n",
    "    \"\"\"One-Hot encode matrix of examples\"\"\"\n",
    "    if not isinstance(image_data, np.ndarray):\n",
    "        image_data = np.array(image_data)\n",
    "\n",
    "    num_colors = 4\n",
    "    examples, rows, cols = image_data.shape\n",
    "    encoded_shape = (examples, rows, cols, num_colors)\n",
    "    encoded_image = np.zeros(encoded_shape)\n",
    "    for i in range(examples):\n",
    "        for j in range(rows):\n",
    "            for k in range(cols):\n",
    "                for l in range(num_colors):\n",
    "                    if l == image_data[i, j, k]:\n",
    "                        encoded_image[i, j, k, l] = 1\n",
    "                    \n",
    "    return encoded_image\n",
    "\n",
    "def preprocess_data(image_data, label_data):\n",
    "    \"\"\"Preprocess and encode image and label data for model training\"\"\"\n",
    "    image_data = one_hot_encode(image_data)\n",
    "    label_data = np.array(label_data)\n",
    "    flattened_data = image_data.reshape(image_data.shape[0], -1)\n",
    "    flattened_data = np.c_[np.ones(len(flattened_data)), flattened_data] \n",
    "    return flattened_data, label_data\n",
    "    \n",
    "def plot_data(title, x_label, y_label, data):\n",
    "    \"\"\"Data should be either a list or tuple, where the list is a list of tuples.\n",
    "    \n",
    "    Tuple format: Data to be plotted, name of data\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    if isinstance(data, list):\n",
    "        for d in data:\n",
    "            ax.plot(d[0], label = d[1])\n",
    "    else:\n",
    "        ax.plot(data[0], label = data[1])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label) \n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0955d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression - Task 1\n",
    "class LogisticRegression:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, X_val, y_val, lr, epsilon, regularization):\n",
    "        self.n = len(X_train)                                           # of training examples\n",
    "        self.d = len(X_train[0])                                        # of features\n",
    "        self.X_train = X_train #np.c_[np.ones(self.n), X_train]         # Training data\n",
    "        self.X_test = X_test                                            # Testing data\n",
    "        self.X_val = X_val                                              # Validation data\n",
    "        self.y_train = y_train                                          # Training classification Labels\n",
    "        self.y_test = y_test                                            # Testing classification Labels\n",
    "        self.y_val = y_val                                              # Validation classification Labels\n",
    "        self.weights = np.zeros(self.d)                                 # Current parameters / weights with d rows\n",
    "        self.lr = lr                                                    # Learning rate   \n",
    "        self.epsilon = epsilon                                          # Early stopping difference\n",
    "        self.regularization, self.Lambda, self.decay = regularization   # Type of regularization, penalty, and decay of the penalty\n",
    "\n",
    "    # Helper methods \n",
    "    # dataset = 0 - train; 1 - val; 2 - test\n",
    "    def dataset_picker(self, dataset = 0):\n",
    "        if dataset == 0:\n",
    "            return self.X_train, self.y_train\n",
    "        elif dataset == 1:\n",
    "            return self.X_test, self.y_test\n",
    "        else:\n",
    "            return self.X_val, self.y_val\n",
    "\n",
    "    # Helper methods \n",
    "    def predict(self, inds=None, dataset = 0):\n",
    "        \"\"\"Compute h_w(x_i) for the provided weight values\"\"\"\n",
    "        X, y = self.dataset_picker(dataset)\n",
    "        if inds is None:\n",
    "            inds = np.arange(len(X))\n",
    "        \n",
    "        dot_product = np.dot(X[inds], self.weights)\n",
    "        return sigmoid(dot_product)\n",
    "\n",
    "    def loss(self, y, p):\n",
    "        \"\"\"Compute the current value of average loss based on predictions\"\"\"\n",
    "        loss = np.mean(-y * np.log(p) - (1 - y) * np.log(1 - p))\n",
    "        if self.regularization == 2:\n",
    "            loss += sum(self.Lambda * np.square(self.weights))\n",
    "        return loss\n",
    "    \n",
    "    def accuracy(self, gold_labels, preds):\n",
    "        pred_labels = self.get_pred_labels(preds)\n",
    "        correct = [1 if pred == gold else 0 for pred, gold in zip(pred_labels, gold_labels)]\n",
    "        count, total = sum(correct), len(correct)\n",
    "        acc = round(count/total*100, 2)\n",
    "        \n",
    "        return acc, count, total\n",
    "    \n",
    "    def predict_loss_acc(self, inds=None, dataset=0):\n",
    "        X, y = self.dataset_picker(dataset)\n",
    "        preds = self.predict(inds, dataset)\n",
    "\n",
    "        loss = self.loss(y, preds)\n",
    "        acc, correct, total = self.accuracy(y, preds)\n",
    "        \n",
    "        return loss, acc\n",
    "\n",
    "    \n",
    "    # Gradient Descent\n",
    "    def gd(self):\n",
    "        \"\"\"Run Gradient Descent to find `parameters` to minimize loss\"\"\"\n",
    "        # Shuffle data before each epoch\n",
    "        # random.shuffle(self.examples)\n",
    "        # for i in range(len(self.examples)):\n",
    "        #errors = self.loss(self.labels, self.predict())\n",
    "        residuals = self.predict() - self.y_train\n",
    "        gradient = np.dot(self.X_train.T, residuals)\n",
    "        self.weights -= self.lr * gradient\n",
    "            \n",
    "    def sgd(self):\n",
    "        \"\"\"Run a single iteration of SGD\"\"\"\n",
    "        # Shuffle data before each epoch\n",
    "        indices_array = np.arange(len(self.X_train))\n",
    "        random.shuffle(indices_array)\n",
    "        \n",
    "        for ind in indices_array:\n",
    "            residual = self.predict(ind) - self.y_train[ind]\n",
    "            gradient = residual * self.X_train[ind]\n",
    "            if self.regularization == 2:\n",
    "                gradient += 2 * self.Lambda * self.weights\n",
    "            self.weights -= self.lr * gradient\n",
    "            \n",
    "\n",
    "    def train_deterministic(self, epochs):\n",
    "        \"\"\"Run GD until # of epochs is exceeded OR convergence\"\"\"\n",
    "        prev = float('inf')\n",
    "        for epoch in range(epochs):\n",
    "            self.gd()\n",
    "            train_loss = self.loss(self.y_train, self.predict())\n",
    "            if epoch % 5 == 0:\n",
    "                print(f\"{epoch} - Loss: {train_loss}\")\n",
    "                \n",
    "            if prev - train_loss < self.epsilon:\n",
    "                print(f\"Stopping early at epoch {epoch} - Loss: {train_loss}\")\n",
    "                break\n",
    "            prev = train_loss\n",
    "            \n",
    "        print(f\"{epoch} - Loss: {train_loss}\")\n",
    "\n",
    "    # Stochastic Gradient Descent\n",
    "    def train_stochastic(self, epochs, display_steps = 1):\n",
    "        \"\"\"Run SGD until # of epochs is exceeded OR convergence\"\"\"\n",
    "        prev_loss = deque([float('inf')])\n",
    "        prev_acc = deque([float('inf')])\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        for epoch in range(epochs):\n",
    "            self.sgd()\n",
    "\n",
    "            loss_train, acc_train = self.predict_loss_acc(dataset=0)\n",
    "            loss_val, acc_val = self.predict_loss_acc(dataset=2)\n",
    "            \n",
    "            self.train_losses.append(loss_train)\n",
    "            self.val_losses.append(loss_val)\n",
    "            self.train_accuracies.append(acc_train)\n",
    "            self.val_accuracies.append(acc_val)\n",
    "                        \n",
    "            mean_loss = sum(prev_loss)/len(prev_loss)\n",
    "            mean_acc = sum(prev_acc)/len(prev_acc)\n",
    "\n",
    "            if epoch % display_steps == 0:\n",
    "                print(f\"LOSS: {epoch} - train: {loss_train}; val: {loss_val}; mean: {mean_loss}\")\n",
    "                print(f\"ACC: {epoch} - train: {acc_train}; val: {acc_val}, mean: {mean_acc}\")\n",
    "            \n",
    "            if abs(mean_loss - loss_val) < self.epsilon:\n",
    "            #if abs(mean_acc - loss_val) < self.epsilon:\n",
    "                print(f\"Stopping early at epoch {epoch}\")\n",
    "                break\n",
    "            prev_loss.append(float(loss_val))\n",
    "            prev_acc.append(float(acc_val))\n",
    "            if len(prev_loss) > 5:\n",
    "                prev_loss.popleft()\n",
    "            if len(prev_acc) > 5:\n",
    "                prev_acc.popleft()\n",
    "\n",
    "            self.Lambda *= self.decay\n",
    "                \n",
    "    # Model Evaluation\n",
    "    def indicator(self, pred):\n",
    "        \"\"\"Returns label 1 if p(y == 1) > .5, 0 if p(y == 1) < .5, and breaks ties randomly\"\"\"\n",
    "        if pred > .5:\n",
    "            return 1\n",
    "        elif pred < .5:\n",
    "            return 0\n",
    "        return np.random.choice([0, 1])\n",
    "    \n",
    "    def get_pred_labels(self, preds):\n",
    "        \"\"\"Converts prediction probabilities into labels\"\"\"\n",
    "        for i in range(len(preds)):\n",
    "            preds[i] = self.indicator(preds[i])\n",
    "            \n",
    "        return preds\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Compute the accuracy of the models predictions for test and training data\"\"\"\n",
    "        probs_train = self.predict(dataset=0)\n",
    "        acc_train, correct_train, total_train = self.accuracy(self.y_train, probs_train)\n",
    "        print(f\"TRAINING ACCURACY: {acc_train}%, {correct_train}/{total_train}\")\n",
    "        \n",
    "        probs_test = self.predict(dataset=1)\n",
    "        acc_test, correct_test, total_test = self.accuracy(self.y_test, probs_test)\n",
    "        print(f\"TESTING ACCURACY: {acc_test}%, {correct_test}/{total_test}\")\n",
    "\n",
    "        plot_data(f\"Loss In Relation to Epochs ({self.n} train samples)\", \"Epochs\", \"Loss\", [(self.train_losses, \"Train\"), (self.val_losses, \"Validation\")])\n",
    "        plot_data(f\"Accuracy In Relation to Epochs ({self.n} train samples)\", \"Epochs\", \"Accuracy\", [(self.train_accuracies, \"Train\"), (self.val_accuracies, \"Validation\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and Preprocess Data\n",
    "data = DataSet()\n",
    "img_gen = ImageGenerator(5000, dataset = data, seed = 718067190)\n",
    "\n",
    "lr = .05\n",
    "epsilon = .0001\n",
    "Lambda, decay = .01, 0.6\n",
    "# 2 ==> L2, 1 ==> L1\n",
    "regularization = (2, Lambda, decay)\n",
    "image_data, label_data = preprocess_data(data.image_data, data.labels)\n",
    "ttv_split = train_test_validation_split(image_data, label_data) # train, test, and validation\n",
    "\n",
    "logistic = LogisticRegression(*ttv_split, lr, epsilon, regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa529d9d-8e5b-444e-8bf9-6c55c636ce20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd = logistic.train_stochastic(20000)\n",
    "predictions = logistic.get_pred_labels(logistic.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8747b-9e69-4e69-b4cb-acf95a1b8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.test()\n",
    "print(f\"SUM OF WEIGHTS: {sum(abs(logistic.weights))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.labels.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87483dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in logistic.weights:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "diagrams = logistic.X_train\n",
    "labels = logistic.y_train\n",
    "\n",
    "diagrams2 = logistic.X_test\n",
    "labels2 = logistic.y_test\n",
    "\n",
    "print(diagrams.shape, labels.shape)\n",
    "print(diagrams2.shape, labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=250)\n",
    "model.fit(diagrams, labels)\n",
    "\n",
    "predictions = model.predict(diagrams2)\n",
    "\n",
    "accuracy = accuracy_score(labels2, predictions)\n",
    "print(\"Test accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2b799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
